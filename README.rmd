---
output:
  md_document:
    variant: markdown_github
---

# Purpose

This is the README where I did all of my rough workings. If you want the clean README please look in my WriteUp folder in this repository.


```{r}

rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.
library(tidyverse)
library(rsample)
library(caret)
library(xgboost)
library(rsample)
library(Ckmeans.1d.dp)


list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
```

```{r IMPORTDATA&cleaning}
master_df <- read.csv("data/games.csv")

#drop unuseful collumns
master_df <- subset(master_df, select = c(-white_id, -black_id, -id, -created_at, -last_move_at))

#Drop any games with less than 11 moves so we can use the first 5 moves
master_df <- master_df %>%
  filter(str_count(moves, "\\S+") >= 11)

#Create a difference variables of the difference in ratings with respect to white such that if white has an elo of 400 and black 500 the difference will be -100
master_df$ratingdiff <- master_df$white_rating - master_df$black_rating

#Extracting the first five moves for White and black
##This removes everything after the first space which leaves the first move in chess notation eg e4 represents the first move for white movinf the pawn to the e4 square
master_df <- master_df %>%
  separate(moves, into = c("whitemove1", "blackmove1", "whitemove2", "blackmove2", "whitemove3","blackmove3", "whitemove4","blackmove4", "whitemove5", "blackmove5"), sep = " ", extra = "drop", fill = "right") 
  
```

```{r Desc1}
#First lets just see the ratio of game outcomes by time controls, rating, rating difference, and type of win (timeout, checkmate and resignation)
library(dplyr)
whitemovepop <- master_df %>%
  count(whitemove1) %>%
  top_n(10) %>%
  arrange(desc(n))

blackmovepop <- master_df %>%
  count(blackmove1) %>%
  top_n(10) %>%
  arrange(desc(n))

# Combine the most common moves for white and black
movepop <- bind_rows(
 mutate(whitemovepop, side = "White", move = whitemove1),
  mutate(blackmovepop, side = "Black", move = blackmove1)
)

# Plot the bar plot

plot1 <- ggplot(movepop, aes(x = fct_inorder(move), y = n, fill = side)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Move 1", y = "Frequency", title = "10 Most Common Move 1 for White and Black") +
  scale_fill_manual(values = c("White" = "gray", "Black" = "black")) +
  theme_minimal() +
  theme(legend.position = "bottom")

plot1
```

```{r Descrip2}
#Now to see the proportions of wins relative to the most popular openings
outcome_proportions <- master_df %>%
  group_by(whitemove1) %>%
  summarize(
    white_wins = sum(winner == "white"),
    black_wins = sum(winner == "black"),
    draws = sum(winner == "draw"),
    total_games = n()
  ) %>%
  mutate(
    white_win_prop = white_wins / total_games,
    black_win_prop = black_wins / total_games,
    draw_prop = draws / total_games
  )


outcome_proportions

filtered_proportions <- outcome_proportions %>%
  filter(whitemove1 %in% c("e4", "d4", "Nf3", "c4", "e3"))

filtered_proportions_long <- tidyr::pivot_longer(filtered_proportions,
                                                 cols = c(white_win_prop, black_win_prop, draw_prop),
                                                 names_to = "outcome",
                                                 values_to = "proportion")


outcomeplot <- ggplot(filtered_proportions_long, aes(x = whitemove1, y = proportion, fill = outcome)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "First Move", y = "Win rate", title = "Win Percentage by Colour for First Moves") +
  scale_fill_manual(values = c("white_win_prop" = "gray", "black_win_prop" = "black", "draw_prop" = "blue"),
                    labels = c("Black Wins", "Draws", "White Wins")) +
  scale_y_continuous(labels = scales::percent) +
  scale_x_discrete(limits = c("e4", "d4", "Nf3", "c4", "e3")) +
  theme_minimal() +
  theme(legend.position = "bottom")

outcomeplot
```




```{r Descrip3}
#Lets look at the differences in time controls
#first lets look at if there is a change in winning depending on if there is added time per move
incrementdf <- master_df %>% 
  separate(increment_code, into = c("base", "increment"), sep = "\\+") %>% 
    mutate(incr = ifelse(increment != 0, "no", "yes")) %>% 
    select(winner, base, increment, incr) %>% 
    group_by(base, incr) %>% 
    summarize(
    white_wins = sum(winner == "white"),
    black_wins = sum(winner == "black"),
    draws = sum(winner == "draw"),
    total_games = n()
  ) %>%
  mutate(
    white_win_prop = white_wins / total_games,
    black_win_prop = black_wins / total_games,
    draw_prop = draws / total_games
  ) %>% 
    ungroup() %>% 
    filter(total_games > 200, base != 5, base != 7) %>% 
    select(base, incr, white_win_prop, black_win_prop, draw_prop) %>% 
    gather(Score, Value, -base, -incr)

#now lets plot a facetwrapped plot to see if there are differences between increments being present or not

incrplot <- ggplot(incrementdf, aes(x = base, y = Value, fill = Score)) +
  geom_bar(stat = "identity", position = "dodge") +
    facet_wrap(~incr, scales = "fixed", nrow = 2)+
  labs(x = "Time Control", y = "Win rate", title = "Win Percentage by Time Control", subtitle = "Grouped by increment or not") +
  scale_fill_manual(values = c("white_win_prop" = "gray", "black_win_prop" = "black", "draw_prop" = "blue"),
                    labels = c("Black Wins", "Draws", "White Wins")) +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal() +
  theme(legend.position = "bottom")

incrplot
```

```{r Descrip4}
#Now lets look at the most common openings
openings <- master_df %>% 
    select(opening_name) %>% 
    separate(opening_name, into = c("opening", "variation"), sep = ": ") %>% 
    group_by(opening) %>% 
    count(opening) %>%
    ungroup() %>% 
    arrange(-n) %>% 
    top_n(10) %>% 
    select(n, opening)

#now we have the top 10 openings lets plot them
pop_openings<- openings %>% 
    ggplot()+
    geom_col(aes(x=opening,y=n))+
                 coord_flip()+
                 theme_classic()
pop_openings
```

```{r}
#Now that we have the most popular openings are lets look at the proportion of winners and losers are
winner_openings <- master_df %>% 
  separate(opening_name, into = c("opening", "variation"), sep = ": ") %>% 
  select(opening, winner) %>% 
  filter(opening %in% c("Sicilian Defense", "French Defense", "Queen's Pawn Game", "Italian Game", "King's Pawn Game", "Ruy Lopez", "English Opening", "Scandinavian Defense", "Caro-Kann Defense", "Scotch Game")) %>% 
  group_by(opening) %>% 
  summarize(
    white_wins = sum(winner == "white"),
    black_wins = sum(winner == "black"),
    draws = sum(winner == "draw"),
    total_games = n()
  ) %>%
  mutate(
    white_win_prop = white_wins / total_games,
    black_win_prop = black_wins / total_games,
    draw_prop = draws / total_games
  ) %>% 
    select(opening, white_win_prop, black_win_prop, draw_prop) %>% 
  gather(Score, Value, -opening)

opening_plot <- winner_openings %>% 
  ggplot(aes(x = opening, y = Value, fill = Score)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Opening", y = "Win rate", title = "Win Percentage by Opening", subtitle = "Most popular 10 openings") +
  scale_fill_manual(values = c("white_win_prop" = "gray", "black_win_prop" = "black", "draw_prop" = "blue"),
                    labels = c("White Wins", "Black Wins", "Draws")) +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank())+
    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8))

opening_plot

    

```

```{r Ratings}
winner_rating<- master_df %>% 
ggplot()+
    geom_point(aes(x=white_rating,y=black_rating,color=winner), alpha=0.5)+
      geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black")

winner_rating
```

```{r}
rating <- master_df %>% 
    select(white_rating, black_rating) 
 
median <- rating %>% 
    summarise(white = median(white_rating), black = median(black_rating))

rating_hist <-master_df %>% 
    ggplot() +
  geom_density(aes(x = white_rating), color = "gray") +
     geom_density(aes(x = black_rating), color = "black") +
     geom_vline(xintercept = 1567, color = "gray", linetype = "dashed") +
  geom_vline(xintercept = 1562, color = "black", linetype = "dashed") +
  labs(title = "Player Rating", x = "Rating", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.ticks.x = element_blank())

rating_hist
```

```{r factorengineering}
library(dplyr)


master_df$whitemove1 <- as.factor(master_df$whitemove1)
master_df$whitemove2 <- as.factor(master_df$whitemove2)
master_df$whitemove3 <- as.factor(master_df$whitemove3)
master_df$whitemove4 <- as.factor(master_df$whitemove4)
master_df$whitemove5 <- as.factor(master_df$whitemove5)

master_df$blackmove1 <- as.factor(master_df$blackmove1)
master_df$blackmove2 <- as.factor(master_df$blackmove2)
master_df$blackmove3 <- as.factor(master_df$blackmove3)
master_df$blackmove4 <- as.factor(master_df$blackmove4)
master_df$blackmove5 <- as.factor(master_df$blackmove5)

master_df$winner <- as.factor(master_df$winner)
master_df$opening_eco <- as.factor(master_df$opening_eco)
master_df$victory_status <- as.factor(master_df$victory_status)
master_df$rated <- as.factor(master_df$rated)
master_df$increment_code <- as.factor(master_df$increment_code)
```

```{r First attempt}
 library(caret)
# set.seed(555)
# split_1  <- initial_split(master_df, prop = 0.7)  # Split the dataset 
# train_2  <- training(split_1)  # Training set
# test_2   <- testing(split_1)  # Test set
# 
# cv <- trainControl(
#   method = "repeatedcv", 
#   number = 10, 
#   repeats = 5
# )
# 
# hyper_grid <- expand.grid(k = seq(2, 25, by = 1))
# 
# knn_fit <- train(
#   winner~ rated + turns + victory_status + white_rating + black_rating + opening_eco + opening_ply, 
#   data = master_df, 
#   method = "knn", 
#   trControl = cv, 
#   tuneGrid = hyper_grid
# )
# 
# knn_fit

#knearest neighbours cannot work with the type of dataset
```

```{r}
# library(xgboost)
# library(caret)
# library(rsample)
# set.seed(555)
# 
# split_1 <- initial_split(master_df, prop = 0.7)  # Split the dataset 
# train_2 <- training(split_1)  # Training set
# test_2 <- testing(split_1)  # Test set
# 
# 
# 
# set.seed(555)
# 
# # Convert categorical variables to factors
# factor_cols <- c("rated", "victory_status", "opening_eco")
# train_2[factor_cols] <- lapply(train_2[factor_cols], as.factor)
# test_2[factor_cols] <- lapply(test_2[factor_cols], as.factor)
# 
# # Perform one-hot encoding
# train_encoded <- model.matrix(~.-1, data = train_2[, c("rated", "victory_status", "opening_eco")])
# test_encoded <- model.matrix(~.-1, data = test_2[, c("rated", "victory_status", "opening_eco")])
# 
# # Combine predictors into a single matrix
# X_train <- cbind(train_2[, c("turns", "white_rating", "black_rating", "opening_ply")], train_encoded)
# X_test <- cbind(test_2[, c("turns", "white_rating", "black_rating", "opening_ply")], test_encoded)
# 
# # Convert labels to factor
# train_labels <- as.factor(train_2$winner)
# test_labels <- as.factor(test_2$winner)
# 
# # Create the DMatrix for XGBoost
# dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.integer(train_labels) - 1)  # Subtract 1 to make labels start from 0
# dtest <- xgb.DMatrix(data = as.matrix(X_test), label = as.integer(train_labels) - 1)
# 
# # Set the parameters for the XGBoost model
# params <- list(
#   objective = "multi:softmax",  # Multiclass classification objective
#   eval_metric = "mlogloss",  # Evaluation metric
#   num_class = 3,  # Number of classes (black, white, draw)
#   nthread = 1,  # Number of threads
#   seed = 555  # Random seed
# )
# 
# # Train the XGBoost model
# xgb_model <- xgboost(
#   data = dtrain,
#   params = params,
#   nrounds = 10,  # Number of boosting rounds (you can adjust this parameter)
#   early_stopping_rounds = 10,  # Early stopping rounds
#   verbose = 0  # Verbosity level
# )
# 
# # Predict using the trained model
# predictions <- predict(xgb_model, dtest)
# 
# # Convert class predictions to labels
# labels <- levels(train_labels)
# class_predictions <- labels[as.integer(predictions) + 1]  # Add 1 to revert back to original labels
# 
# # Assess the model performance
# # Assuming you have the actual test labels in test_2$winner
# accuracy <- sum(class_predictions == test_labels) / length(test_labels)


```

```{r Startover}
# library(recipes)
# library(xgboost)
# set.seed(555)
# split_1  <- initial_split(master_df, prop = 0.7)  # Split the dataset 
# train_2  <- training(split_1)  # Training set
# test_2   <- testing(split_1)  # Test set
# 
# boost_prep <- recipe(data = train_2, winner ~ rated + white_rating + black_rating + ratingdiff + opening_eco + opening_ply+ whitemove1 + whitemove2+ whitemove3+ whitemove4+ whitemove5 + blackmove1 + blackmove2 + blackmove3 + blackmove4 + blackmove5 ) %>% 
#     prep(training = train_2, retain = TRUE) %>%
#   juice()
# 
# X <- as.matrix(boost_prep[setdiff(names(boost_prep), "winner")])
# Y <- boost_prep$winner
#     
# set.seed(555)
# chessboost <- xgboost(
#   data = X,
#   label = Y,
#   nrounds = 6000,
#   objective = "multi:softmax",
#   early_stopping_rounds = 50, 
#   nfold = 10,
#   params = list(
#     eta = 0.1,
#     max_depth = 3,
#     min_child_weight = 3,
#     subsample = 0.8,
#     num_class = 2,
#     colsample_bytree = 1.0),
#   verbose = 0
# )  
# 
# # minimum test CV RMSE
# min(chessboost$evaluation_log$test_rmse_mean)

#This did not work either
```

```{r XGBOOST}

# library(recipes)
# library(xgboost)
# set.seed(555)
# split_1  <- initial_split(master_df, prop = 0.7)  # Split the dataset 
# train_2  <- training(split_1)  # Training set
# test_2   <- testing(split_1)  # Test set
# factor_cols <- c("rated", "victory_status", "opening_eco","whitemove1", "whitemove2", "whitemove3", "whitemove4", "whitemove5", "blackmove1", "blackmove2", "blackmove3", "blackmove4", "blackmove5")
# train_2[factor_cols] <- lapply(train_2[factor_cols], as.factor)
# test_2[factor_cols] <- lapply(test_2[factor_cols], as.factor)
# 
# # Perform one-hot encoding
# train_encoded <- model.matrix(~.-1, data = train_2[, c("rated", "victory_status", "opening_eco","whitemove1", "whitemove2", "whitemove3", "whitemove4", "whitemove5", "blackmove1", "blackmove2", "blackmove3", "blackmove4", "blackmove5")])
# test_encoded <- model.matrix(~.-1, data = test_2[, c("rated", "victory_status", "opening_eco","whitemove1", "whitemove2", "whitemove3", "whitemove4", "whitemove5", "blackmove1", "blackmove2", "blackmove3", "blackmove4", "blackmove5")])
# 
# # Combine predictors into a single matrix
# X_train <- cbind(train_2[, c("white_rating", "black_rating", "opening_ply", "ratingdiff" )], train_encoded)
# X_test <- cbind(test_2[, c( "white_rating", "black_rating", "opening_ply", "ratingdiff")], test_encoded)
# 
# # Convert labels to factor
# train_labels <- as.factor(train_2$winner)
# test_labels <- as.factor(test_2$winner)
# 
# # Create the DMatrix for XGBoost
# dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.integer(train_labels) - 1)  # Subtract 1 to make labels start from 0
# dtest <- xgb.DMatrix(data = as.matrix(X_test))
# 
# # Set the parameters for the XGBoost model
# params <- list(
#   objective = "multi:softmax",  # Multiclass classification objective
#   eval_metric = "mlogloss",  # Evaluation metric
#   num_class = 3,  # Number of classes (black, white, draw)
#   nthread = 1,  # Number of threads
#   seed = 555  # Random seed
# )
# 
# # Train the XGBoost model
# xgb_model <- xgboost(
#   data = dtrain,
#   params = params,
#   nrounds = 10,  # Number of boosting rounds (you can adjust this parameter)
#   early_stopping_rounds = 10,  # Early stopping rounds
#   verbose = 1  # Verbosity level
# )
# 
# # Predict using the trained model
# predictions <- predict(xgb_model, dtest)
# 
# # Convert class predictions to labels
# labels <- levels(train_labels)
# class_predictions <- labels[as.integer(predictions) + 1]  # Add 1 to revert back to original labels
# 
# # Assess the model performance
# # Assuming you have the actual test labels in test_2$winner
# accuracy <- sum(class_predictions == test_labels) / length(test_labels)
# 
# #I ran into problems that there were more move types in the training data than in the test so i instead categorise each move as a unique number so this issue is eliminated
```

```{r numXGBOOST}
library(recipes)
library(xgboost)
master_dfull<- master_df %>% 
    separate(increment_code, into = c("base", "increment"), sep = "\\+") %>% 
    mutate(base = as.numeric(base), increment = as.numeric(increment))


set.seed(555)
split_1 <- initial_split(master_dfull, prop = 0.7)  # Split the dataset 
train_2 <- training(split_1)  # Training set
test_2 <- testing(split_1)  # Test set
factor_cols <- c("opening_eco", "whitemove1", "whitemove2", "whitemove3", "whitemove4", "whitemove5", "blackmove1", "blackmove2", "blackmove3", "blackmove4", "blackmove5")
train_2[factor_cols] <- lapply(train_2[factor_cols], as.character)
test_2[factor_cols] <- lapply(test_2[factor_cols], as.character)

# Assign unique numerical identifiers to categorical variables
for (col in factor_cols) {
  unique_vals <- unique(c(train_2[[col]], test_2[[col]]))
  train_2[[col]] <- as.integer(factor(train_2[[col]], levels = unique_vals))
  test_2[[col]] <- as.integer(factor(test_2[[col]], levels = unique_vals))
}

# Combine predictors into a single matrix
X_train <- cbind(train_2[, c("white_rating", "black_rating", "opening_ply", "ratingdiff", "base", "increment")], train_2[factor_cols])
X_test <- cbind(test_2[, c("white_rating", "black_rating", "opening_ply", "ratingdiff", "base", "increment")], test_2[factor_cols])

# Convert labels to factor
train_labels <- as.factor(train_2$winner)
test_labels <- as.factor(test_2$winner)

# Set the parameters for the XGBoost model
params <- list(
  objective = "multi:softmax",  # Multiclass classification objective
  eval_metric = "mlogloss",  # Evaluation metric
  num_class = 3,  # Number of classes (black, white, draw)
  nthread = 1,  # Number of threads
  seed = 555  # Random seed
)

# Create the DMatrix for XGBoost
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.integer(train_labels) - 1)  # Subtract 1 to make labels start from 0
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = as.integer(test_labels) - 1)

# Train the XGBoost model
xgb_model <- xgboost(
  data = dtrain,
  params = params,
  nrounds = 1000,  # Number of boosting rounds (you can adjust this parameter)
  early_stopping_rounds = 10,  # Early stopping rounds
  verbose = 1  # Verbosity level
)

# Predict using the trained model
predictions <- predict(xgb_model, dtest)

# Convert class predictions to labels
labels <- levels(test_labels)
class_predictions <- labels[as.integer(predictions) + 1]  # Add 1 to revert back to original labels

# Assess the model performance
accuracy <- sum(class_predictions == test_labels) / length(test_labels)
accuracy

vip_plot1 <- vip::vip(xgb_model )

# Feature importance using gain

importance_gain <- xgb.importance(model = xgb_model)
importance_gain

xgboost::xgb.ggplot.importance(importance_gain)

library(caret)

# Convert the predicted class labels to a factor with levels
class_predictions <- factor(class_predictions, levels = levels(test_labels))

#confusion matrix
cm <- confusionMatrix(data = class_predictions, reference = test_labels)

treesplot <- xgb.plot.multi.trees(feature_names = names(master_dfull), 
                     model = xgb_model)


```

```{r cv}
# set.seed(123)
# 
# # Create the DMatrix for XGBoost
# dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.integer(train_labels) - 1)  # Subtract 1 to make labels start from 0
# 
# # Set the parameters for the XGBoost model
# params <- list(
#   objective = "multi:softmax",  # Multiclass classification objective
#   eval_metric = "mlogloss",  # Evaluation metric
#   num_class = 3,  # Number of classes (black, white, draw)
#   eta = 0.5,
#   max_depth = 3,
#   min_child_weight = 3,
#   subsample = 0.8,
#   colsample_bytree = 1.0
# )
# 
# # Perform cross-validation
# cv_result <- xgb.cv(
#   data = dtrain,
#   params = params,
#   nrounds = 6000,
#   early_stopping_rounds = 50,
#   nfold = 10,
#   verbose = 0
# )
# 
# # Get the minimum test CV logloss
# min_logloss <- min(cv_result$evaluation_log$test_mlogloss_mean)
# 
# # Print the minimum test CV logloss
# print(min_logloss)

```

```{r gridsearch}
hyper_grid <- expand.grid(
  eta = 0.01,
  max_depth = 3,
  min_child_weight =  3,
  subsample = 0.5,
  colsample_bytree = c(0.5, 0.75, 1),
  gamma = c(0, 1, 10, 100, 1000),
  lambda = c(0, 1e-2, 0.1, 1, 100, 1000, 10000),
  alpha = c(0, 1e-2, 0.1, 1, 100, 1000, 10000),
  rmse = 0,
  trees = 0
)

# Grid search
for (i in seq_len(nrow(hyper_grid))) {
  set.seed(555)
  dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.integer(train_labels) - 1)
  params <- list(
    objective = "multi:softmax",
    eval_metric = "mlogloss",
    num_class = 3,
    eta = hyper_grid$eta[i],
    max_depth = hyper_grid$max_depth[i],
    min_child_weight = hyper_grid$min_child_weight[i],
    subsample = hyper_grid$subsample[i],
    colsample_bytree = hyper_grid$colsample_bytree[i],
    gamma = hyper_grid$gamma[i],
    lambda = hyper_grid$lambda[i],
    alpha = hyper_grid$alpha[i]
  )
  
  cv_result <- xgb.cv(
    data = dtrain,
    params = params,
    nrounds = 2000,
    early_stopping_rounds = 50,
    nfold = 10,
    verbose = 0
  )
  
  hyper_grid$rmse[i] <- min(cv_result$evaluation_log$test_mlogloss_mean)
  hyper_grid$trees[i] <- cv_result$best_iteration
}

# Filter and sort the results
filtered_results <- hyper_grid %>%
  filter(rmse > 0) %>%
  arrange(rmse)

# Print the filtered results
glimpse(filtered_results)

hg1 <- options(xtable.comment = FALSE)
hg1 <- xtable(filtered_results, caption = "Hypergrid Full Sample")
hg1
```

```{r finalfit}

# optimal parameter list
params <- list(
    eval_metric = "mlogloss",  
  num_class = 3,  
  nthread = 1, 
  eta = 0.01,
  max_depth = 4,
  min_child_weight = 3,
  subsample = 0.5,
  colsample_bytree = 0.5
)


# train final model
xgb.fit.final <- xgboost(
  params = params,
  data = dtrain,
  label = Y,
  nrounds = 1029,
objective = "multi:softmax",
verbose = 0
)

# Predict using the trained model
predictions <- predict(xgb.fit.final, dtest)

# Convert class predictions to labels
labels <- levels(test_labels)
class_predictions <- labels[as.integer(predictions) + 1]  # Add 1 to revert back to original labels

# Assess the model performance
accuracy <- sum(class_predictions == test_labels) / length(test_labels)
accuracy

```

```{r Importance}
library(vip)

#Alternate use xgb.importance
importance2 <- xgb.importance(model = xgb.fit.final)
importance_plot<- xgboost::xgb.ggplot.importance(importance2)
importance_plot
```

```{r}
#Lets now get two more models for above and below the median elo
master_dflow<- master_df %>% 
    separate(increment_code, into = c("base", "increment"), sep = "\\+") %>% 
    mutate(base = as.numeric(base), increment = as.numeric(increment)) %>% 
    filter(white_rating < 1567, black_rating < 1562)


set.seed(555)
split_1 <- initial_split(master_dflow, prop = 0.7)  # Split the dataset 
train_2 <- training(split_1)  # Training set
test_2 <- testing(split_1)  # Test set
factor_cols <- c("opening_eco", "whitemove1", "whitemove2", "whitemove3", "whitemove4", "whitemove5", "blackmove1", "blackmove2", "blackmove3", "blackmove4", "blackmove5")
train_2[factor_cols] <- lapply(train_2[factor_cols], as.character)
test_2[factor_cols] <- lapply(test_2[factor_cols], as.character)

# Assign unique numerical identifiers to categorical variables
for (col in factor_cols) {
  unique_vals <- unique(c(train_2[[col]], test_2[[col]]))
  train_2[[col]] <- as.integer(factor(train_2[[col]], levels = unique_vals))
  test_2[[col]] <- as.integer(factor(test_2[[col]], levels = unique_vals))
}

# Combine predictors into a single matrix
X_train <- cbind(train_2[, c("white_rating", "black_rating", "opening_ply", "ratingdiff", "base", "increment")], train_2[factor_cols])
X_test <- cbind(test_2[, c("white_rating", "black_rating", "opening_ply", "ratingdiff", "base", "increment")], test_2[factor_cols])

# Convert labels to factor
train_labels <- as.factor(train_2$winner)
test_labels <- as.factor(test_2$winner)

# Set the parameters for the XGBoost model
params <- list(
  objective = "multi:softmax",  # Multiclass classification objective
  eval_metric = "mlogloss",  # Evaluation metric
  num_class = 3,  # Number of classes (black, white, draw)
  nthread = 1,  # Number of threads
  seed = 555  # Random seed
)

# Create the DMatrix for XGBoost
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.integer(train_labels) - 1)  # Subtract 1 to make labels start from 0
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = as.integer(test_labels) - 1)

# Train the XGBoost model
xgb_model <- xgboost(
  data = dtrain,
  params = params,
  nrounds = 1000,  # Number of boosting rounds (you can adjust this parameter)
  early_stopping_rounds = 10,  # Early stopping rounds
  verbose = 1  # Verbosity level
)

# Predict using the trained model
predictions <- predict(xgb_model, dtest)

# Convert class predictions to labels
labels <- levels(test_labels)
class_predictions <- labels[as.integer(predictions) + 1]  # Add 1 to revert back to original labels

# Assess the model performance
accuracy <- sum(class_predictions == test_labels) / length(test_labels)
accuracy

vip::vip(xgb_model )

# Feature importance using gain
library(Ckmeans.1d.dp)

importance_gain <- xgb.importance(model = xgb_model)
importance_gain

xgboost::xgb.ggplot.importance(importance_gain)

library(caret)

# Convert the predicted class labels to a factor with levels
class_predictions <- factor(class_predictions, levels = levels(test_labels))

# Create the confusion matrix
cm <- confusionMatrix(data = class_predictions, reference = test_labels)

# Print the confusion matrix
print(cm)

```

```{r grid2}
hyper_grid <- expand.grid(
  eta = 0.01,
  max_depth = 3,
  min_child_weight =  3,
  subsample = 0.5,
  colsample_bytree = c(0.5, 0.75, 1),
  gamma = c(0, 1, 10, 100, 1000),
  lambda = c(0, 1e-2, 0.1, 1, 100, 1000, 10000),
  alpha = c(0, 1e-2, 0.1, 1, 100, 1000, 10000),
  rmse = 0,
  trees = 0
)

# Grid search
for (i in seq_len(nrow(hyper_grid))) {
  set.seed(555)
  dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.integer(train_labels) - 1)
  params <- list(
    objective = "multi:softmax",
    eval_metric = "mlogloss",
    num_class = 3,
    eta = hyper_grid$eta[i],
    max_depth = hyper_grid$max_depth[i],
    min_child_weight = hyper_grid$min_child_weight[i],
    subsample = hyper_grid$subsample[i],
    colsample_bytree = hyper_grid$colsample_bytree[i],
    gamma = hyper_grid$gamma[i],
    lambda = hyper_grid$lambda[i],
    alpha = hyper_grid$alpha[i]
  )
  
  cv_result <- xgb.cv(
    data = dtrain,
    params = params,
    nrounds = 2000,
    early_stopping_rounds = 50,
    nfold = 10,
    verbose = 0
  )
  
  hyper_grid$rmse[i] <- min(cv_result$evaluation_log$test_mlogloss_mean)
  hyper_grid$trees[i] <- cv_result$best_iteration
}

# Filter and sort the results
filtered_results3 <- hyper_grid %>%
  filter(rmse > 0) %>%
  arrange(rmse) %>% 
    head(15)

# Print the filtered results
glimpse(filtered_results3)

hg2 <- options(xtable.comment = FALSE)
hg2 <- xtable(filtered_results3, caption = "Hypergrid Bottom Half of the Sample")
hg2
```


```{r}
master_dfhigh<- master_df %>% 
    separate(increment_code, into = c("base", "increment"), sep = "\\+") %>% 
    mutate(base = as.numeric(base), increment = as.numeric(increment)) %>% 
        filter(white_rating > 1567, black_rating > 1562)



set.seed(555)
split_1 <- initial_split(master_dfhigh, prop = 0.7)  # Split the dataset 
train_2 <- training(split_1)  # Training set
test_2 <- testing(split_1)  # Test set
factor_cols <- c("opening_eco", "whitemove1", "whitemove2", "whitemove3", "whitemove4", "whitemove5", "blackmove1", "blackmove2", "blackmove3", "blackmove4", "blackmove5")
train_2[factor_cols] <- lapply(train_2[factor_cols], as.character)
test_2[factor_cols] <- lapply(test_2[factor_cols], as.character)

# Assign unique numerical identifiers to categorical variables
for (col in factor_cols) {
  unique_vals <- unique(c(train_2[[col]], test_2[[col]]))
  train_2[[col]] <- as.integer(factor(train_2[[col]], levels = unique_vals))
  test_2[[col]] <- as.integer(factor(test_2[[col]], levels = unique_vals))
}

# Combine predictors into a single matrix
X_train <- cbind(train_2[, c("white_rating", "black_rating", "opening_ply", "ratingdiff", "base", "increment")], train_2[factor_cols])
X_test <- cbind(test_2[, c("white_rating", "black_rating", "opening_ply", "ratingdiff", "base", "increment")], test_2[factor_cols])

# Convert labels to factor
train_labels <- as.factor(train_2$winner)
test_labels <- as.factor(test_2$winner)

# Set the parameters for the XGBoost model
params <- list(
  objective = "multi:softmax",  # Multiclass classification objective
  eval_metric = "mlogloss",  # Evaluation metric
  num_class = 3,  # Number of classes (black, white, draw)
  nthread = 1,  # Number of threads
  seed = 555  # Random seed
)

# Create the DMatrix for XGBoost
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.integer(train_labels) - 1)  # Subtract 1 to make labels start from 0
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = as.integer(test_labels) - 1)

# Train the XGBoost model
xgb_model <- xgboost(
  data = dtrain,
  params = params,
  nrounds = 1000,  # Number of boosting rounds (you can adjust this parameter)
  early_stopping_rounds = 10,  # Early stopping rounds
  verbose = 1  # Verbosity level
)

# Predict using the trained model
predictions <- predict(xgb_model, dtest)

# Convert class predictions to labels
labels <- levels(test_labels)
class_predictions <- labels[as.integer(predictions) + 1]  # Add 1 to revert back to original labels

# Assess the model performance
accuracy <- sum(class_predictions == test_labels) / length(test_labels)
accuracy

vip::vip(xgb_model )

# Feature importance using gain
library(Ckmeans.1d.dp)

importance_gain <- xgb.importance(model = xgb_model)
importance_gain

xgboost::xgb.ggplot.importance(importance_gain)

library(caret)

# Convert the predicted class labels to a factor with levels
class_predictions <- factor(class_predictions, levels = levels(test_labels))

# Create the confusion matrix
cm <- confusionMatrix(data = class_predictions, reference = test_labels)



```

```{r grid3}
hyper_grid <- expand.grid(
  eta = 0.01,
  max_depth = 3,
  min_child_weight =  3,
  subsample = 0.5,
  colsample_bytree = c(0.5, 0.75, 1),
  gamma = c(0, 1, 10, 100, 1000),
  lambda = c(0, 1e-2, 0.1, 1, 100, 1000, 10000),
  alpha = c(0, 1e-2, 0.1, 1, 100, 1000, 10000),
  rmse = 0,
  trees = 0
)
# Grid search
for (i in seq_len(nrow(hyper_grid))) {
  set.seed(555)
  dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.integer(train_labels) - 1)
  params <- list(
    objective = "multi:softmax",
    eval_metric = "mlogloss",
    num_class = 3,
    eta = hyper_grid$eta[i],
    max_depth = hyper_grid$max_depth[i],
    min_child_weight = hyper_grid$min_child_weight[i],
    subsample = hyper_grid$subsample[i],
    colsample_bytree = hyper_grid$colsample_bytree[i],
    gamma = hyper_grid$gamma[i],
    lambda = hyper_grid$lambda[i],
    alpha = hyper_grid$alpha[i]
  )
  
  cv_result <- xgb.cv(
    data = dtrain,
    params = params,
    nrounds = 2000,
    early_stopping_rounds = 50,
    nfold = 10,
    verbose = 0
  )
  
  hyper_grid$rmse[i] <- min(cv_result$evaluation_log$test_mlogloss_mean)
  hyper_grid$trees[i] <- cv_result$best_iteration
}

# Filter and sort the results
filtered_results4 <- hyper_grid %>%
  filter(rmse > 0) %>%
  arrange(rmse) %>% 
    head(15) %>% 
    head(15)

# Print the filtered results
glimpse(filtered_results4)

hg3 <- options(xtable.comment = FALSE)
hg3 <- xtable(filtered_results4, caption = "Hypergrid Top Half")
hg3
```

